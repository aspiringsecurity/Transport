import numpy as np
import pandas as pd
import torch
from copy import copy

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class GatedReccurentUnitMeta(type):
    """
    The Meta Class for DCGRUCell
    """
    def __new__(self, class_name, bases, attrs):
        """
        Executes upon creation of a new class
        @param class_name: the class name
        @param bases: base classes
        @param attrs: class attributes
        """
        def graph_convolution(self, inputs, state, output_size, bias_start=0.0):
            """
            Convolution of inputs combined with state by building sparse matrix from Privacy Preserving algorithms
            using Parameter module
            @param inputs: graph data inputs sent to RNN
            @param state: hidden state from RNN
            @param output_size: output_size generated by graph convolution algorithm
            @param bias_start:
            @return:
            """

            # Reshape input and state to (batch_size, num_nodes, input_dim/state_dim)
            batch_size = inputs.shape[0]
            inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1))
            state = torch.reshape(state, (batch_size, self._num_nodes, -1))
            # Combine inputs and hidden state
            inputs_and_state = torch.cat([inputs, state], dim=2)
            input_size = inputs_and_state.size(2)

            x = inputs_and_state
            x0 = x.permute(1, 2, 0)  # (num_nodes, total_arg_size, batch_size)
            x0 = torch.reshape(x0, shape=[self._num_nodes, input_size * batch_size])
            x = torch.unsqueeze(x0, 0)

            if self._max_diffusion_step == 0:
                pass
            else:
                # iterate through privacy-preserving algorithms
                for support in self._supports:
                    # privacy preserving matrix will be sparse matrix
                    x1 = torch.sparse.mm(support, x0)
                    x = self._concat(x, x1)

                    # apply diffusion step as per DCRNN
                    for k in range(2, self._max_diffusion_step + 1):
                        x2 = 2 * torch.sparse.mm(support, x1) - x0
                        x = self._concat(x, x2)
                        x1, x0 = x2, x1

            # calculate the number of matrices for shape evaluation
            num_matrices = len(self._supports) * self._max_diffusion_step + 1  # Adds for x itself.
            # reshape inputs_and_state tensor
            x = torch.reshape(x, shape=[num_matrices, self._num_nodes, input_size, batch_size])
            x = x.permute(3, 1, 2, 0)  # (batch_size, num_nodes, input_size, order)
            # put batch_size first
            x = torch.reshape(x, shape=[batch_size * self._num_nodes, input_size * num_matrices])

            # get weights from graph convolution parameter module
            weights = self._gconv_params.get_weights(shape=(input_size * num_matrices, output_size))
            x = torch.matmul(x, weights)  # (batch_size * self._num_nodes, output_size)

            # get biases from graph convolution parameter module
            biases = self._gconv_params.get_biases(output_size, bias_start)
            x += biases
            # Reshape res back to 2D: (batch_size, num_node, state_dim) -> (batch_size, num_node * state_dim)
            return torch.reshape(x, [batch_size, self._num_nodes * output_size])

        def fully_connected(self, inputs, state, output_size, bias_start=0.0):
            """
            Create a Fully connected layer as a Parameter
            @param inputs:
            @param state:
            @param output_size:
            @param bias_start:
            @return:
            """
            batch_size = inputs.shape[0]
            # reshape inputs for fully connected layer
            inputs = torch.reshape(inputs, (batch_size * self._num_nodes, -1))
            # reshape hidden state for fully connected layer
            state = torch.reshape(state, (batch_size * self._num_nodes, -1))
            # combine inputs and state
            inputs_and_state = torch.cat([inputs, state], dim=-1)
            input_size = inputs_and_state.shape[-1]
            # get weights from fully connected parameters
            weights = self._fc_params.get_weights(shape=(input_size, output_size))
            value = torch.sigmoid(torch.matmul(inputs_and_state, weights))
            # get biases from fully connected parameters
            biases = self._fc_params.get_biases(output_size, bias_start)
            value += biases

            return value

        @staticmethod
        def _build_sparse_matrix(L):
            """
            Builds a sparse matrix for privacy-preserving algorithms computations
            @param L:
            @return:
            """
            L = L.tocoo()
            indices = np.column_stack((L.row, L.col))
            # this is to ensure row-major ordering to equal torch.sparse.sparse_reorder(L)
            indices = indices[np.lexsort((indices[:, 0], indices[:, 1]))]
            L = torch.sparse_coo_tensor(indices.T, L.data, L.shape, device=device)

            return L

        @staticmethod
        def _concat(x, x_):
            """
            Concats two input tensors
            @param x:
            @param x_:
            @return:
            """
            x_ = x_.unsqueeze(0)
            return torch.cat([x, x_], dim=0)

        attributes = copy(attrs)

        # set the methods upon creation of class using meta classes
        attributes['graph_convolution'] = graph_convolution
        attributes['fully_connected'] = fully_connected
        attributes['_build_sparse_matrix'] = _build_sparse_matrix
        attributes['_concat'] = _concat

        return type(class_name, bases, attributes)
